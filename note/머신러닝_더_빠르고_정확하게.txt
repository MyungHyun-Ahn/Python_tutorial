데이터 전처리

데이터를 더 좋은 형식으로 만들어 주는 것

Feature Scaling : 입력변수 크기를 조정해준다

ex : 변수의 단위 차이가 너무 클 때 조정

경사 하강법을 좀 더 빨리할 수 있게 도와준다.

min-max normalization

최솟값, 최댓값을 이용해서 데이터의 크기를 0과 1사이로 바꾸어준다.

y = ( x - min ) / ( max - min )

데이터가 커지면 손실이 급격히 변한다.

feature scaling을 하게되면 경사하강그래프가 원에 가까워진다. & 최소점 방향으로 일직선에 가깝게 내려온다.

선형 회귀 뿐만 아니라 경사 하강법을 사용하는 모든 알고리즘의 속도를 빠르게 해준다.

표준화 standardization

One-hot Encoding

머신러닝에 사용하는 데이터 : 수치형 데이터 / 범주형 데이터

범주형 데이터를 수치로 바꾸어주어야함 >> 숫자로 표현

그렇게 하기 위해 One-hot Encoding 사용

각 카테고리를 하나의 새로운 열로 만들어주는 방법

열의 값을 0 또는 1로 채워줌으로 범주형 데이터에 크고 작은 관계가 생기는 것을 막을 수 있음

정규화 Regularization

편향 / 분산

직선 모델 보다는 곡선 모델이 더 정확할 때도 있음
>> 편향 Bias 가 높다고 한다.
>> 편향이 낮은 모델 구불구불

데이터 셋 별로 모델의 성능 차이가 많이 나면 분산이 높다.

곡선 모델 >> 성능 차이가 크다
직선 모델 >> 성능 차이가 작다 >> 분산이 작다.

편향이 높은 모델은 너무 간단해서 주어진 데이터의 관계를 잘 학습하지 못한다.
편향이 낮은 모델은 주어진 데이터의 관계를 아주 잘 학습한다.
분산은 다양한 테스트 데이터가 주어졌을 때 모델의 성능이 얼마나 일관적인지를 나타낸다.

일반적으로 편향과 분산은 하나가 줄어들수록 하나는 늘어나는 관계
> 편향 분산 트레이드오프 Bias Variance Tradeoff
> 편향과 분산, 과소적합과 과적합의 적당한 밸런스를 찾아내야 함

직선 모델 

복잡도가 떨어지기 때문에 곡선 관계를 학습할 수 없다.
어떤 데이터가 주어져도 일관적인 성능을 낸다.
> 편향이 높고, 분산이 낮은 모델 > 트레이닝 데이터에 과소적합 되었다. Underfit

곡선 모델

training 데이터에 대한 성능은 아주 높다.
처음보는 testing 데이터에 대한 성능은 떨어진다.
> 편향이 낮고, 분산이 높은 모델 > 트레이닝 데이터에 과적합 되었다. Overfit

정규화 : 세타 값들이 너무 커지는 것을 막을 수 있는 방법

모델 과적합 현상을 방지해주는 방법 중 하나

L1 정규화

손실 함수 + 정규화 항

좋은 가설 함수의 기준 : Training data에 대한 오차도 작고 세타 값들도 작아야지 좋은 가설 함수

손실 함수 J의 값이 클수록 가설 함수가 안좋다는 뜻
> 세타 값들의 절댓값 또는 크기를 모두 더해주면 됨 > 세타(0)은 과적합과 상관이 없기 때문에 더하지 않음
세타 값들이 커지는 것에 대한 패널티를 람다라는 수를 곱해주어서 패널티를 줄 수 있다.

람다 = 100 세타값들이 조금만 커져도 손실 함수가 굉장히 커짐 > 세타를 줄이는 게 우선
람다 = 0.01 세타값들이 많이 커져도 손실 함수가 별로 안 커짐 > 평균 제곱 오차를 줄이는 게 우선
 
L1 정규화를 적용하는 모델은 Lasso Regression 또는 Lasso 모델이라고 함

L2 정규화

세타 값의 절댓값이 아닌 제곱 값을 더해줌

L2 정규화를 적용하는 모델은 Rige Regression 또는 Ridge 모델이라고 함

L1 정규화와 L2 정규화의 차이점

L1 정규화는 여러 세타값들을 0으로 만들어줌 > 모델에 중요하지 않다고 생각되는 속성들을 아예 버리는 것
L2 정규화는 세타값들을 0으로 만들기보다는 조금씩 줄여줌 > L1 처럼 중요하지 않더라도 없애지는 않는 것


모델 평가와 하이퍼파라미터 고르기

k겹 교차 검증 k-fold cross validation

운좋게 test set 에서만 성능이 좋을 수도 안좋을 수도 있는데 이를 해결하기 위해 k겹 교차 검증 사용

데이터 셋을 k개로 나눔 > 1개를 테스트 셋으로 사용하고 k-1개를 트레이닝 셋으로 사용 > 반복하며 k번 사용 > 평균 성능을 계산
5개로 나누면 5겹 교차검증 > 10개로 나누면 10겹 교차검증

하이퍼 파라미터 

학습을 하기 전에 미리 정해 줘야 하는 변수 또는 파라미터들

model = Lasso(alpha=0.01, max_iter=1000)
alpha : 손실 함수의 정규화 항에 곱해지는 상수
max_iter : 경사 하강법을 몇 번 할 건지 정해주는 상수

하이퍼 파라미터에 어떤 값을 넣어주느냐에 따라 성능에 큰 차이가 있을 수 있다.

좋은 파라미터를 고르는 방법 >> Grid Search

구글링을 통해 scikit learn 에 사용되는 디폴트 값을 찾기
> 표를 만들고 값을 채우기
> 가장 좋은 값을 선택


